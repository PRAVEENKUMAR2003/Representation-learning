{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYmK3dxDUKQ1"
      },
      "outputs": [],
      "source": [
        "# Prerparing dataset triplet for siamese network\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "num_classes = 10\n",
        "approx_samples_per_class = 15\n",
        "\n",
        "reshaped_x_train = []\n",
        "reshaped_y_train = []\n",
        "anchor_idx = []\n",
        "positive_idx = []\n",
        "negative_idx = []\n",
        "anchor_y = []\n",
        "positive_y = []\n",
        "negative_y = []\n",
        "\n",
        "for i in range(num_classes):\n",
        "    class_indices = np.where(y_train == i)[0]\n",
        "    num_samples = min(approx_samples_per_class, class_indices.shape[0])\n",
        "    selected_indices = np.random.choice(class_indices, size=num_samples, replace=False)\n",
        "    reshaped_x_train.append(x_train[selected_indices])\n",
        "    reshaped_y_train.append(y_train[selected_indices])\n",
        "\n",
        "reshaped_x_train = np.array(reshaped_x_train)\n",
        "reshaped_y_train = np.array(reshaped_y_train)\n",
        "x_train = reshaped_x_train\n",
        "print(\"Reshaped x_train shape:\", reshaped_x_train.shape)\n",
        "print(\"Reshaped y_train shape:\", reshaped_y_train.shape)\n",
        "for i in range(len(x_train)):\n",
        "    for j in range(len(x_train[i])):\n",
        "        for k in range(j+1, len(x_train[i])):\n",
        "            for l in range(len(x_train)):\n",
        "                if l==i:\n",
        "                    continue\n",
        "                for m in range(len(x_train[l])):\n",
        "                    anchor_idx.append(x_train[i,j])\n",
        "                    positive_idx.append(x_train[i,k])\n",
        "                    negative_idx.append(x_train[l,m])\n",
        "                    anchor_y.append(i)\n",
        "                    positive_y.append(i)\n",
        "                    negative_y.append(l)\n",
        "\n",
        "\n",
        "print(len(anchor_idx))\n",
        "anchor_idx=np.array(anchor_idx)\n",
        "positive_idx=np.array(positive_idx)\n",
        "negative_idx=np.array(negative_idx)\n",
        "anchor_y=np.array(anchor_y)\n",
        "positive_y=np.array(anchor_y)\n",
        "negative_y=np.array(negative_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import stuffs\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras\n",
        "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Input, Flatten, Dense, Lambda, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "metadata": {
        "id": "ZPO5cIbrnMp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbJsC9YyUPDl"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "def VGG16():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dense(4096, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "feature = VGG16()\n",
        "image_a = Input(shape=(28,28), name='image_input_a')\n",
        "image_b = Input(shape=(28,28), name='image_input_b')\n",
        "image_c = Input(shape=(28,28), name='image_input_c')\n",
        "\n",
        "feature_vector_A = feature(image_a)\n",
        "feature_vector_B = feature(image_b)\n",
        "feature_vector_C = feature(image_c)\n",
        "\n",
        "def euclidean_distance(a, b):\n",
        "    return tf.sqrt(tf.reduce_sum(tf.square(a - b), axis=-1))\n",
        "\n",
        "class CustomLayer(keras.layers.Layer):\n",
        "    def custom_loss(self, output_intermediate_a, output_intermediate_b, output_intermediate_c):\n",
        "        output_a = output_intermediate_a\n",
        "        output_b = output_intermediate_b\n",
        "        output_c = output_intermediate_c\n",
        "        distance_positive = tf.reduce_sum(tf.square(output_a[:,0:1000] - output_b[:,0:1000]), axis=1)\n",
        "        distance_negative = tf.reduce_sum(tf.square(output_a[:,0:1000] - output_c[:,0:1000]), axis=1)\n",
        "        loss = tf.maximum(distance_positive - distance_negative + 0.1, 0.0)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        return K.mean(loss)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output_intermediate_a = inputs[0]\n",
        "        output_intermediate_b = inputs[1]\n",
        "        output_intermediate_c = inputs[2]\n",
        "        loss = self.custom_loss(output_intermediate_a, output_intermediate_b, output_intermediate_c)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        return inputs\n",
        "y = CustomLayer()([feature_vector_A, feature_vector_B, feature_vector_C])\n",
        "\n",
        "discriminator = Sequential([\n",
        "    Dense(10, input_shape=(4096,), activation='sigmoid')\n",
        "])\n",
        "\n",
        "class_vector_A = discriminator(y[0])\n",
        "class_vector_B = discriminator(y[1])\n",
        "class_vector_C = discriminator(y[2])\n",
        "\n",
        "\n",
        "model2 = keras.Model([image_a, image_b, image_c], [class_vector_A, class_vector_B, class_vector_C])\n",
        "\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "\n",
        "    y_true_onehot_1 = tf.one_hot(tf.cast(y_true[:,0], dtype=tf.int32), depth=10)\n",
        "    y_true_onehot_1 = tf.squeeze(y_true_onehot_1, axis=0)\n",
        "    y_pred_onehot_1 = y_pred[:,0]\n",
        "    loss1 = tf.keras.losses.CategoricalCrossentropy()(y_true_onehot_1, y_pred_onehot_1)\n",
        "    y_true_onehot_2 = tf.one_hot(tf.cast(y_true[:,1], dtype=tf.int32), depth=10)\n",
        "    y_true_onehot_2 = tf.squeeze(y_true_onehot_2, axis=0)\n",
        "    y_pred_onehot_2 = y_pred[:,1]\n",
        "    loss2 = tf.keras.losses.CategoricalCrossentropy()(y_true_onehot_2, y_pred_onehot_2)\n",
        "    y_true_onehot_3 = tf.one_hot(tf.cast(y_true[:,2], dtype=tf.int32), depth=10)\n",
        "    y_true_onehot_3 = tf.squeeze(y_true_onehot_3, axis=0)\n",
        "    y_pred_onehot_3 = y_pred[:,2]\n",
        "    loss3 = tf.keras.losses.CategoricalCrossentropy()(y_true_onehot_3, y_pred_onehot_3)\n",
        "\n",
        "    return loss1+loss2+loss3\n",
        "\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Model([image_a, image_b, image_c], [class_vector_A, class_vector_B, class_vector_C])\n"
      ],
      "metadata": {
        "id": "q8M7l6WxYoq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q_CNNgpppQs"
      },
      "outputs": [],
      "source": [
        "model2.compile(optimizer=tf.keras.optimizers.Adam(0.00005), loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRbAVrvQT8iy"
      },
      "outputs": [],
      "source": [
        "model2.fit([anchor_idx,positive_idx,negative_idx], [to_categorical(anchor_y),to_categorical(positive_y),to_categorical(negative_y)], validation_split=0.2,epochs = 100, batch_size = 2048)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Input(shape=(28,28), name='image_input')\n",
        "feature_vector = feature(image)\n",
        "class_vector = discriminator(feature_vector)\n",
        "model = keras.Model(image, class_vector)\n"
      ],
      "metadata": {
        "id": "Q2dLGppCdexm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TadekhHmtOeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "5AnIzgYQ7eyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(anchor_idx, to_categorical(anchor_y), epochs = 100, batch_size = 2048,shuffle=True,validation_data=(x_test, to_categorical(y_test)))\n"
      ],
      "metadata": {
        "id": "TQXuNBCstZ7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAmxmKvlnhve"
      },
      "outputs": [],
      "source": [
        "filename = \"/content/drive/MyDrive/mnist/Siamesemodel_triple.joblib\"\n",
        "import joblib\n",
        "joblib.dump(model2, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n38OQFC3oI0A"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import custom_object_scope\n",
        "\n",
        "with custom_object_scope({'CustomLayer': CustomLayer}):\n",
        "    loaded_model = joblib.load('/content/drive/MyDrive/mnist/Siamesemodel_triple.joblib')\n",
        "model = loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install opencv-python\n"
      ],
      "metadata": {
        "id": "pUo2dQw3nzQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "# Initialize empty lists for X_train and y_train\n",
        "X_train_augmented = []\n",
        "y_train_augmented = []\n",
        "(x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "for j in range(len(x_train)):\n",
        "    for i in range(100):\n",
        "        original_image = x_train[j]\n",
        "\n",
        "        x_offset = np.random.randint(0, 75 - 28)\n",
        "        y_offset = np.random.randint(0, 75 - 28)\n",
        "\n",
        "        start_angle = -45\n",
        "        end_angle = 45\n",
        "        num_angles = end_angle - start_angle + 1\n",
        "\n",
        "        for angle in range(start_angle, end_angle + 1, 10):\n",
        "\n",
        "            dark_image = np.zeros((75, 75))\n",
        "            rotation_matrix = cv2.getRotationMatrix2D((original_image.shape[1] / 2, original_image.shape[0] / 2), angle, 1.0)\n",
        "            rotated_image = cv2.warpAffine(original_image, rotation_matrix, (original_image.shape[1], original_image.shape[0]))\n",
        "            dark_image[x_offset:x_offset+28, y_offset:y_offset+28] = rotated_image\n",
        "\n",
        "            X_train_augmented.append(dark_image)\n",
        "            y_train_augmented.append(original_image)\n",
        "    print(j,\"done\")\n",
        "\n",
        "X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)\n"
      ],
      "metadata": {
        "id": "ZgDVcHcqnpBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import random\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "def get_random_sample(input_list):\n",
        "    if len(input_list) > 50:\n",
        "        random_sample = random.sample(input_list, 50)\n",
        "        return random_sample\n",
        "    else:\n",
        "        return input_list\n",
        "import tensorflow as tf\n",
        "\n",
        "def extract_tensor_at_index(input_tensor, index):\n",
        "    extracted_tensor = tf.gather(input_tensor, index, axis=1)\n",
        "    reshaped_tensor = tf.expand_dims(extracted_tensor, axis=-1)\n",
        "    return reshaped_tensor\n",
        "\n",
        "train_images = train_images.reshape(-1, 784) / 255.0\n",
        "test_images = test_images.reshape(-1, 784) / 255.0\n",
        "\n",
        "inputs = tf.keras.Input(shape=(784,), name='input')\n",
        "print(inputs)\n",
        "layer_outputs = []\n",
        "num_layers = 20\n",
        "\n",
        "for i in range(num_layers):\n",
        "    x = []\n",
        "    for j in range(len(layer_outputs)):\n",
        "        x.append(layer_outputs[j])\n",
        "    if (i>784):\n",
        "        layer_input = tf.concat(x + [], axis=1) if i > 0 else inputs\n",
        "    else:\n",
        "        layer_input = tf.concat(x + [inputs], axis=1) if i > 0 else inputs\n",
        "    layer = tf.keras.layers.Dense(1, activation='relu', name='n{}'.format(i+1))(layer_input)\n",
        "    layer_outputs.append(layer)\n",
        "    print(i)\n",
        "\n",
        "output_input = tf.concat(layer_outputs[:]+[] , axis=1)\n",
        "\n",
        "output = tf.keras.layers.Dense(10, activation='softmax', name='output')(output_input)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "E2v6TtUfn8Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLlH35HMnkiA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3bAb2tBvoR3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "dk_QqUeOoR3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(anchor_idx, to_categorical(anchor_y), epochs = 100, batch_size = 2048,shuffle=True,validation_data=(x_test, to_categorical(y_test)))\n"
      ],
      "metadata": {
        "id": "OdTCZ6FNoR3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQGZUuCgzr5j"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}